\documentclass[10pt,twocolumn,letterpaper]{article}

% \usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}

% Include other packages here, before hyperref.
\usepackage{subfig}
\newcommand{\subsubfloat}[2]{%
  \begin{tabular}{@{}c@{}}#1\\#2\end{tabular}%
}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\usepackage{multirow}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}


\begin{document}
%%%%%%%%% Preface
\onecolumn
\pagenumbering{gobble}
\include{preface}

%%%%%%%%% TITLE
\twocolumn
\pagenumbering{arabic}
\newpage
\title{Learn transferable image representations with noisy labels for semantic image segmentation}

\author{Jihong Ju\\
Faculty of Electrical Engineering, Mathematics and Computer Science \\
Mekelweg 4, 2628 CD Delft\\
{\tt\small j.ju@student.tudelft.nl}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}

% Noisy data exists
% Transfer learning
% Noises affect feature transferability
% Binarizing classes
% Modify loss for incomplete segmentation

In some domains of interest, there exist noisy segmentations in addition to a limited amount of perfect segmentations.
Noisy segmentations can, for instance, come from crowdsourcing platforms.
The existence of noisy datasets motivates us to consider if it is possible to utilize noisy segmentations in training better image segmentation models with limited training samples.
We focus on to pre-train robustly transferable feature representations with potentially incomplete, mislabeled segmentations.
In this paper, we investigate the influence of these segmentation noises on model transferability in an experimental setup with synthesized noises.
With observing a negative impact of objects mislabeling on feature transferability, we discover that combining object categories as one foreground class improves feature transferability for a small training set corrupted heavily with random labels.
Besides, a sigmoidal loss for the background class is proposed to balance precision and recall when training with incomplete segmentations.
% Compared to simply changing class weights, the proposed sigmoidal loss down-weights the losses for confident predictions and unconfident predictions differently.
Experiments demonstrate that replacing the cross-entropy loss with a sigmoidal loss for the background class achieves better pre-training and fine-tuning performances in the presence of incomplete segmentation.


\end{abstract}

%%%%%%%%% BODY TEXT

\input{introduction}

\input{related}

\input{robustness}

\input{pulearning}

\input{experiments}

\input{discussion}

\input{conclusion}


{\small
\bibliographystyle{plain}
\bibliography{references}
}

\clearpage
\appendix
\input{appendix_a}
\input{appendix_b}
\input{appendix_c}
\input{appendix_de}

\end{document}
