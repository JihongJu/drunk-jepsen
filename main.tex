\documentclass[10pt,twocolumn,letterpaper]{article}

% \usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{makecell}

% Include other packages here, before hyperref.
\usepackage{subfig}
\newcommand{\subsubfloat}[2]{%
  \begin{tabular}{@{}c@{}}#1\\#2\end{tabular}%
}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\usepackage{multirow}


\begin{document}
%%%%%%%%% Preface
\onecolumn
\pagenumbering{gobble}
\include{preface}

\twocolumn
\pagenumbering{arabic}
%%%%%%%%% TITLE
\newpage
\title{Learn transferable features for semantic image segmentation in the presence of label noise}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}


%%%%%%%%% ABSTRACT
\begin{abstract}
Given the mis-segmentation robustness of feature transferability discussed in section \ref{subsec:robustness}, we proposed to include mis-segmented objects to learn pre-trained model.
Misclassification noises had also negative impact on weights transferability, but categorizing classes into categories or even binarizing can alleviate the randomness of labels while still achieve comparable fine-tuning performance.
Lastly, inexhaustive segmentation can have significant influence on feature transferability and it can be compensate partially by modifying the loss function for the deep learning models.
We proposed a particular class dependent loss in order to not over-punish confident contrary predictions.
The proposed loss led to better pre-trainig performance as well as better fine-tuning performance with a synthesized dataset as discussed in section \ref{subsec:pulearning}.
The types of segmentation noises we concentrated on in this study are mis-segmentation, misclassification and inexhaustive segmentation.

\end{abstract}

%%%%%%%%% BODY TEXT
\input{draft}

\input{introduction}

\input{related}

\input{robustness}

\input{pulearning}

\input{experiments}

\input{discussion}

\input{conclusion}


{\small
\bibliographystyle{plain}
\bibliography{references}
}

\clearpage
\input{appendices}

\end{document}
