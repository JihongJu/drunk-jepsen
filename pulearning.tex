\section{Positive and Unlabeled Learning}
\label{sec:pulearning}

\noindent \textit{This part should explain the necessarity of Positive and Unlabeled Learning setup, including the importance to make a difference between inexaustive annot. and misclassification.}

\noindent
We discussed in Section \ref{sec:robustness} that misclassification and inexhaustive annotation can have negative influences on feature transferability, which is undesirable when we pre-train weights with noisy data.
Methods to compensate these errors are therefore necessary to train better representation with a certain number of annotated images.
In practice, misclassification error is less likely to \textit{dorminate}, meaning that the misclassified rate is often not larger than the correct rate.
By contrast, unannotated instances can be dominant for a large-scale dataset, especially when misannotated objects are included for training.
For example, the existence of one misannotated toy dog does not mean that all toy dogs are annotated as dogs.
If misannotated objects are treated the same as correctly annotated ones as proposed in Section \ref{sec:robustness}, the unannotated ``toy dogs'' may cause the problem of inexhaustive annotations and lead to worse fine-tuning performance.
\footnote{J: Extra experiment to support this: 50\% misannotated + 50\% unannotated.}
Therefore, we explored methods to compensate inexhaustive annotations for segmentation in this section.

% \cite{reed2014training,sukhbaatar2014training,patrini2016making,jindal2016learning}

%%%%%%%% TEXT PU Learning setup
\paragraph{Formulation}
\noindent \textit{This part should formulate the problem with a probability model and make clear difference between model for synthesizating and model to fit.}
\noindent
When we synthesized errors in Section \ref{sec:robustness}, we assumed that  all label errors occurred to each segment instead of each pixel.
This is helpful when we already know the
However, which pixels belong to the same segment is unknown when a model is trained with noisy labels only.
prediction for each pixel is made independently though the corresponding receptive fields is overlaped.
Therefore, we instead assume label errors all occured independently
Reasons:

$p(\tilde{y_{ij}} \vert x, y_{ij})$.

This is a strong assumption for practical problems
,and may lead to future works

This model is easy to apply when we have the perfect annotations and want to generate noisy labels, but it is not as easy when we observe noisy labels and want to recover the correct ones.

% It is nevertheless difficult to fit such a NNAR model directly because it is difficult to estimate of $p(e \vert x,y)$ with limited number of samples.
% An alternatie model is the \textit{noisy at random (NAR)} model in which the occurence of errors $e$ are independent to $x$ only on $y$: $p(\tilde{y} \vert y)p(y \vert x)$
% Such \textit{Noisy at random (NAR)}
$p(\tilde{y_{ij}} \vert y_{ij})$


%%%%%%%% TEXT Modeling
\paragraph{Weighted Logistic Regression}
\noindent \textit{This part should discuss the linear model for observing positive conditioning on true positive and its relationship to changing the class weight.}


%%%%%%%% TEXT Exponential loss
\paragraph{Exponential Loss for unlabeled examples}
\noindent
\textit{This part should explain why the exponential loss could perform better than the cross-entropy loss, potentially with a figure of 2D Gaussians.}
The ``soft'' bootstrapping loss in \cite{reed2014training} is actually equivalent to a softmax regression with \textit{minimum entropy regularization}\cite{grandvalet2005semi} which was originally proposed for semi-supervised learning.
Minimum entropy regularization encourages the model to have a high confidence in predicting labels.

%%%%%%%% TEXT Expontial loss FADE IN

\paragraph{Implementation details}
\noindent \textit{This paragraph should explain fade-in was introduced to avoid all-positive inital prediction;}

\noindent

%%%%%%%% TEXT Imbalanced
\noindent
\textit{This part should explain the influence of the imbalanced problem and how to overcome.}



%%%%%%%% FIGURE MOONS
\begin{figure*}
\begin{center}
% \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
   \includegraphics[width=0.95\linewidth]{img/moons.png}
\end{center}
   \caption{2D moons dataset with non-linear separable decision boudary. Four hundreds samples per class were drawn randomly from two interleaving half circles with noises added with a minor standard deviation. A \textbf{red circle} indicates an example labelled as positive whilst a \textbf{blue square} indicates the example has a negative label. The \textbf{leftmost} figures have complete positive labels, meaning the positive and negative labels are all correct, whereas, in \textbf{the other figures} only half of the positives were correctly labelled and the rest were mixed with the negative samples. The \textbf{background colors} represent the probability for the area to be positive given by the classifier trained with the given samples and labels: \textbf{red} for high probability areas, \textbf{blue} for low probability areas and \textbf{white} for the class transition areas, i.e.decision boundaries. The \textbf{size of the markers} in the top row denotes the per-class normalized training losses and the \textbf{size of the markers} in the bottom row the per-class normalized derivatives w.r.t the output of the last layer for the trained Multilayer Perceptron (MLP) with the different losses.}
\label{fig:moons}
\end{figure*}


%%%%%%%% FIGURE Losses
\begin{figure}[t]
\centering
% \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=1.05\linewidth]{img/losses}
\caption{The Logistic Loss, Weighted Logistic Loss, Exponential Loss and their dirivatives with respect to the model output.}
\label{fig:losses}
\end{figure}


%%%%%%%% FIGURE Varying positive annotating percetage
\begin{figure}[t]
\centering
   \includegraphics[width=\linewidth]{img/pu_vs_pn}
\caption{Varying percentage of annotated positives 10\%, 20\%, 50\%, 80\% and 100\% with images from CIFAR10 as the positives and images from CIFAR110 as the negatives.}
\label{fig:pct_annotating}
\end{figure}

%%%%%%%% TABLE CIFAR10
\begin{table}[t]
\resizebox{\columnwidth}{!}{
\centering
\begin{tabular}{ll|llll}
Annotation  & Loss & acc. & prec. & rec. & $F_1$ \\
\hline
Complete    & CrossEntropyU.   & $0.87\pm0.01$ & $0.88\pm0.01$ & $0.82\pm0.01$ & $0.85\pm0.01$ \\
50\%(P+N)   & CrossEntropyU.   & $0.83\pm0.01$ & $0.84\pm0.01$ & $0.78\pm0.01$ & $0.80\pm0.01$ \\
50\%P+U     & CrossEntropyU.   & $0.64\pm0.04$ & $0.93\pm0.08$ & $0.34\pm0.02$ & $0.44\pm0.06$ \\
50\%P+U     & WeightedU.       & $0.78\pm0.01$ & $0.75\pm0.01$ & $0.75\pm0.01$ & $0.76\pm0.01$ \\
50\%P+U     & ExponentialU.    & $0.82\pm0.01$ & $0.86\pm0.01$ & $0.73\pm0.01$ & $0.78\pm0.01$ \\
50\%P+U     & BootstrapHard    & $0.74$ & $0.81$ & $0.60$ & $0.67$ \\
\end{tabular}
}
\caption{Image classification with positive examples partially annotated. The complete dataset contains images from CIFAR10 as the \textbf{positive} (P) set and images from CIFAR110 as the \textbf{negative} (N) set. The unannotated positive examples from P set construct the \textbf{unlabeled} (U) set together with the N set.}
\end{table}


%%%%%%%% TABLE
\begin{table}[t]
\resizebox{\columnwidth}{!}{
\centering
\begin{tabular}{ll|llll}
Annotation  & Loss & pixel acc. & mean acc. & mean IU & f.w. IU \\
\hline
Complete    & CrossEnt.U    &  &  & & \\
50\%(P+N)   & CrossEnt.U    & & & & \\
50\%P+U     & CrossEnt.U    & & & & \\
50\%P+U     & WeightedU        &  &  & & \\
50\%P+U     & ExponentialU     &  &  & & \\
50\%P+U     & BootstrapHard    &  &  & & \\
50\%P+U     & DropoutReg. & & & & \\
\end{tabular}
}
\caption{Image semantic segmentation with images contain single instance only from the PASCAL VOC2011 segmentation dataset. The complete \textbf{positive} (P) set denotes the foreground instances and the \textbf{negative} (N) set consists of the background. The unannotated instances from P set construct the \textbf{unlabeled} (U) set together with the N set.}
\end{table}
