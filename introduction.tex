\section{Introduction}
\label{introduction}

%%%%%%%% TEXT Lack of perfect annotations
\noindent
\textit{Why noisy labels?:This paragraph should discuss the difficulties for collecting perfect segmentation annotations on a large scale}

\noindent
The recent success of deep neural networks benefits from the availability of large-scale supervised datasets such as ILSVRC\cite{russakovsky2015imagenet}.
However, collecting a dataset for semantic image segmentation on a large scale can be expensive and time-consuming, especially when error-free labels are required.
Enormous efforts have been made to create the ``gold standard'' annotations for the current benchmark segmentation datasets\cite{everingham2015pascal,mottaghi2014role,lin2014microsoft}.
\footnote{M: Do we actually have a reference for that?  Or other proof?\\J: I think the preparation methods described in these papers can be supportive. Microsoft COCO even mentioned the total working hours in the paper.}
%Millions of images are available through Flikr, ImageNet and many other sources on the Internet but only a few of them \cite{everingham2015pascal,mottaghi2014role,lin2014microsoft} have been well-annotated for semantic segmentation tasks.
%The largest segmentation dataset, COCO2014\cite{lin2014microsoft}, contains annotations for only 164,000 training images, smaller by a factor of 10 than the ILSVRC2012 dataset with 1,281,167 labeled training images.
These datasets allow the deep neural network models for semantic segmentation \cite{long2015fully,zheng2015conditional} to develop assuming the perfect segmentation ground truth exists, where perfect means that all the instances were annotated, no non-target object was misannotated, and no instance was misclassified.
However, it is natural for human beings to make mistakes due to the lack of expertise, the inherent ambiguity of tasks or unconscious bias.
Strong supervision is required to correct the mistakes, including double-checking the annotations over and over again and ensembling opinions from multiple annotators.
%Otherwise, it may lead to annotations that contain misannotated objects, unannotated instances and misclassified instances.
In some cases, for example in the medical imaging, the ``gold standard'' itself can be ambiguous and cause disagreement among different annotators.
Also, there are some freely available labels, which may or may not be accurate, for specific problems.
For example, one can use digital maps, like OpenStreetMap, to annotate aerial images, but such segmentation annotations constructed from maps suffer from the incomplete annotation as well as registration problems.\cite{mnih2012learning}
%There are also crowdsourcing platforms like Pl\@ntNet can provide noisy labels on a large scale.
This motivates us to explore how to learn from these noisy annotations.

\noindent
\textit{Why representation?: This paragraph should discuss the idea of noise-robust representation}

\noindent
Deep convolutional neural networks (DCNN) based models often contain two principle components: a stack of convolutional layers to extract hierarchical features and a few  task-specific layers to fit the training objectives.
Both parts are important to achieve good performance because they are trained jointly in an end-to-end manner via back propagation.
The convolutional features were proved ``transferable'' to a new dataset\cite{yosinski2014transferable} or even to a different task\cite{girshick2014rich}.
The state-of-art DCNN based semantic image segmentation models relies on transfering the pre-trained convolutional filters as well.\cite{long2015fully}
A typical method to pre-train the convolutional filters is to train a classification model with the large-scale ILSVRC dataset \cite{russakovsky2015imagenet}
However, this method constrains the semantic image segmentation models to have the same CNN architecture as the image classification models.
The CNN design for semantic image segmentation does not necessarily follow the design of image classification architectures.
The segmentation models need both global and local information to predict the category and give a fine segmentation, whereas the classification models care less about local information for object localization.
For instance, the presence of the max-pooling layers enable the following convolutional filters to have larger receptive fields but, at the same time, reduce the resolution of the features.
Additional upsampling layers, can recover the shape of the output segmentation but cannot fully recover the information thrown away.
This first-pooling-and-then-upsampling pipeline can result in coarse segmentation output \cite{chen2016deeplab} with non-shape boundaries and blob-like shapes.
\footnote{M: Also for this claim, I think we need a reference or something like that. Or other proof indeed...  In addition, I wonder whether we can explain why this may be the case? J: Yes, I can refer to a paragraph in the intro of CRFasRNN and enrich the discussion a bit.}
%The coarse output can be refined with Conditional Random Field (CRF) inference\cite{zheng2015conditional,chen2016deeplab}.
\noindent
Alternatively, one can also extract convolutional features with semantic segmentation tasks.
But it is more difficult to collect well-annotated dataset for semantic image segmentation than for object recognition.
A large number of annotated images are of great value to train sufficiently generalised representation and avoid overfitting, given the ``data-hungry'' nature of DCNNs.
\footnote{M: For the rest a bit vague... what do we really mean by suffer? Maybe this becomes clear later in the intro...? J: Refrased.}
Allowing the existence noisy annotations could help signicantly increase the number of annotated images and the number of training samples could compensate the impact of annotation errors.
We will further discuss this in the related works.

% %%%%%%%% TEXT Summarize
\noindent
\textit{This paragraph should summarize the main ideas.}

\noindent
The different levels of the hierarchical features in DCNNs are believed to play different roles in extracting information from the images.
The low-level features process the local information within small neighborhood and the high-level features ensemble information from lower-level features to extract abstract information.
The high-level features were found significantly dependent on the exact categories compared to the low-level features which show extraordinary category independency.\cite{yosinski2014transferable}
Previous studies\cite{sukhbaatar2014training,patrini2016making} have shown that training with noisy labels can lead to significant higher classification errors than training with clean labels if the total number of training samples are fixed.
It is nevertheless unclear how the annotation errors would influence the learned multiple level features.
We made a hypothesis that annotation errors do not necessarily lead to a ``bad representation'' because the ``generality'' of low-level features may contribute to a robustness to the rrors when we transfer the learned features to a new dataset with new categories.
% We then explored methods to learn image representation in the presence of annotation noise.
% \footnote{M: This needs a bit more explaining, I think.  To me this step is absolutely nontrivial.}

%%%%%%%% TEXT Table of contents
\noindent
\textit{Table of contents}

\noindent
In the next section, we summarized the related works.
In Section \ref{sec:formulation} we formulate the annotation errors into three categroies: misannotation, misclassification and incomple annotation.
We tested our hypothesis in Section \ref{sec:objectness}, studying whether the misannotation and misclassification had an impact on learning ``transferable'' features.
In Section \ref{sec:pulearning} we connected training with inexaustive annotations to Positive and Unlabeled Learning.
%Features learned by predicting the pixel objectness with inexaustive annotations were then validated with experiments described in Section \ref{sec:results}.


% %%%%%%%% TEXT Semantic segmentation is different from classification
% \textit{This paragraph should explain the difference between classification and semantic segmentation.}
%
% %%%%%%%% TEXT Missing positive label is different
% \textit{This paragraph should explain the difference between inexaustive/imprecise and misclassification.}
% Classification with label noise
