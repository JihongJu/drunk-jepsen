\section{Discussion}
\label{sec:discussion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% Binarizing classes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% We proposed to learn representations with binary segmentation when objects mislabelling dominates the pre-training dataset.
% Training binary segmentations can also be relevant when there are multiple segmentation datasets for pre-training, and category overlappings and affinities prevent from combining multiple datasets into one.

% In our experiment, the limited amounts of training images, the low-resolution of images and the constraint capacity of the FCN-AlexNet model may explain that more precise labels cannot improve the fine-tuning performance for the pre-trained models.
% In general, a trade-off between precise but less ccurate labels and more accurate but less precise labels need to be made to train better transferable features, given a particular dataset.
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% Influence of label noises
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Datasets with not only label errors but also segmentation errors}
In practice, datasets may also contain segmentation errors such as imprecise boundaries, over-segmenting and under segmenting the objects.
Our proposed method of learning representation with segmentation data do not take these types of label noises into account.
The investigation of the influence of segmentation noises on the learned representations is left for future works.

% When we simulate the label noises in our experiments, we assume unsegmented objects and mislabeled objects occur independently to the shape and appearance of objects.
% In practice, some categories may have a higher probability to be mislabeled due to its ambiguity in shapes or appearances, such as bear and teddy bear.
% Similarly, ambiguous objects are more likely to be missing than easily recognizable objects.
% Experiments on a real dataset with both clean and noisy segmentation are valuable to validate that our findings.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% sigmoid loss
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% \paragraph{Advantages for the sigmoid loss}
% Firsly, the sigmoid loss for the negative class benefits from not punishing predictions with high confidence more than predictions with less high confidence.
%
% The sigmoid loss saturates for confident predictions and the corresponding derivative is closed to zero.
% The update of model weights is mainly contributed by the uncertain predictions during optimization as demonstrated in Figure \ref{fig:moonsdiff}.
% In other words, the model updates with an emphasization for the examples near the decision boundary.
% As a consequence, the model e when the decision confident predictions for all training examples.
% This effect can be interpreted that the sigmoid loss encourages confident predictions.

% The hard bootstrapping loss by \cite{reed2014training} has a ``soft'' alternative which is equivalent to the minimum entropy regularization.
% Both the class-dependent sigmoid loss for PU learning and the minimum regularization scheme favors low-density separations of input features.
% This similar in the sigmoid loss and the bootstrapping loss explains why the sigmoid loss has a similar performance as the hard bootstrapping loss.

\paragraph{Disadvantages for the sigmoid loss}

First of all, we are not able to determine what is the threshold when the sigmoid loss saturates.
A generalized logistic function may be used to replace the normal logistic function as the activation function to achieve a more flexible S-shape and the tuning where the loss saturates.
For example, a parametrized sigmoid loss for the negative class could be $\alpha (\frac{1}{1+\exp{(\beta z_)}})^{\gamma}$, where $z$ is the model output for the negative class, $\alpha$ is the scale factor, $\gamma$ affects where the loss starts, $\beta$ determines where the loss saturates.
Future investigation for this parametrized general sigmoid loss and the corresponding choices of the hyperparmeters is required to achieve potentially better classification performance.

Secondly, a loss saturates in the regions of confident predictions can have its disadvantages:
(1) If a classifier makes incorrect predictions with high confidence, it tends to keep being wrong for these examples and emphasize predictions by itself.
(2) Punishing confident predictions more than uncertain predictions with the logistic loss is a design of choice for neural networks to optimize more effectively, whereas the sigmoid loss breaks it.
These factors determine that the sigmoid loss often performs worse than the logistic loss when the dataset contains only correct labels or a few noisy labels.
There is a trade-off to make between punishing and not punishing more for confident predictions, based on the prior knowledge: an estimation of the noisy negative labels percentage.

% The sum of sigmoid loss for multiple lacks the probabilistic ground as the sum of logistic loss which is equivalent to minimize the multiplication of independent probabilities $p(y_0 \vert x_0) \cdot p(y_1 \vert x_1) \dots p(y_n \vert x_n)$.


\paragraph{The difference between learning with positive and unlabeled data and learning with incomplete segmentations}
In Section \ref{introduction}, we argue that learning in the presence of unlabeled foreground pixels is similar to learning with positive and unlabeled data.
Despite the similarities between the two, there is also a difference between learning with unlabeled foreground pixels and learning with positive and unlabeled examples.
Each example in the normal PU learning setup is independent of each other, whereas the pixels in images are not.
In practice, there is often a spatial dependence for pixels of being labeled or unlabeled.
When we apply the sigmoid loss to the background class for learning segmentation moels with incomplete segmentations, we assume that the probability for a foreground pixel of being labeled as the background is independent of its neighbor pixels.
A method to interpret the spatial dependence for pixels of being labeled in the model can potentially further improve the segmentation performance.

% Another difference between incomplete segmentation and a normal positive and unlabeled learning problem is that pixels for objects of various categories can be unlabeled.
% Alternatively, one can apply a one-vs-all strategy, with which the normal logistic loss is used for positive classes while the weighted, sigmoid and bootstrapping loss can be used for the negative class.




%%%%%%%% confidence
% The problem of weighting negative examples is that it assumes the probability for a negative label being wrong is independent of the underlying distribution of inputs.
% % However, perceptual similar examples are more likely to have the same label, and the negative label is probably wrong if they are assigned contrary labels, supposing the positive labels are always correct.
% Given a nonrandom model, the confidence of a model prediction conveys information about the underlying inputs distribution.
% A confident, positive prediction indicates the example is more likely to be positive than to be negative.
% Therefore, we instead assumed that the probability of mislabeling for a negative label is correlated to the prediction confidence of a trained model.
% In other words, we assumed the confident contrary prediction is more likely to be mislabeled than unconfident examples.

% Upside:
% \begin{itemize}
%   \item treat easy/hard classifications differently
%   \item not over-punish confident positive prediction for negatively labeled examples
% \end{itemize}
%
% Downside:
% \begin{itemize}
%   \item Optimization diffilculty introduced as a result of non-convex objective
% \end{itemize}

% The sigmoid loss was introduced in \cite{tax2016class} to get rid of the effect of outliers.
% In our case, the negative examples given confident predictions by classifier can be considered as outliers.

% Another challenge of difficulty encountered in implementingin extending sigmoid negative loss to multi-class scenario

% \paragraph{The relationship between PU learning and Imbalanced learning}

% Imbalanced
% Easily classified negatives comprise
% the majority of the loss and dominate the gradient. While
% Î± balances the importance of positive/negative examples, it
% does not differentiate between easy/hard examples

% \paragraph{Future works}
%
% \begin{itemize}
%   \item Parameterizing exponential unlabeled loss to determine boundaries of confident and unconfident predictions
%   \item Take into account label noise spatial dependence for neighboring pixels
%   \item Experiment with over-segmentation and under-segmentation noises (negative influence expected)
%   \item Experiment with real datasets
% \end{itemize}

% Trade-offs need to be made between the impact of by label noise and the gain of a larger dataset.
