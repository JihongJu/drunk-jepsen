\section{Related work}
\label{related}

\paragraph{Semantic Image Segmentation with Deep Neural Nets}

J. Long et.al.\cite{long2015fully} defined a skip architecture to combine semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations and transfered the learned representations from the contemporray classification networks into fully convolutional networks.
L. Chen et.al.\cite{chen2016deeplab} removed the last few max pooling layers of the CNNs and upsampled the corresponding filters to avoid the reduced feature resolution by the pooling layers. An additional fully connected Conditional Random Field (CRF) was added to refine the coarse last layer output for better localization performance.
S. Zheng et.al.\cite{zheng2015conditional} integrate the CRFs-based probabilistic graphical modeling with CNNs in an end-to-end framework.

\paragraph{Transfer Learning}
The first-layer features in the modern CNNs are often observed converging to either Gabor filters or color blobs, regardless the exact learning objectives and the training dataset.
This pheonomen is called the \textit{generality} of the first-layer features.
By contrast, the last-layer features depend significantly on the learning objective and dataset and they are called \textit{specific}.\cite{yosinski2014transferable}
Yosinski et.al.\cite{yosinski2014transferable} studied the transition from general to specific for the features in the intermediate layers by measuring how much the tranformed  pre-trained features boost the fine-tuning performance on a new dataset, i.e. the ``transferability'' of the features.
They found features from several bottom layers, not only the first layer, were ``transferable'' to a new dataset, meaning that they were not specific for a particular category but were shared across categories.
This discovery led to our hypothesis that the general features can be more robust to annotation errors, either object misannotation or instance misclassidication, than the specific features.
We used the same measure as Yosinki et.al. did to quantitatively measure the ``transferability'' of the features and reported the robustness to instance misannotation and instance misclassification for the learned representation.

\paragraph{Unsupervised and semi-supervised pre-training}
Apart from supervised pre-training, one can also obtain the pre-trained features with unsupervised or semi-supervised pre-training.
Vincent et al.\cite{vincent2010stacked} trained multilevel representations robust to corrupted inputs with stacked denoising auto-encoders.
Masci et al.\cite{masci2011stacked} presented a stacked convolutional auto-encoder unsupervised pre-training for hierarchical feature extraction.
Hinton et al.\cite{hinton2006fast} proposed a greedy learning algorithm to train \textit{deep belief nets} one layer at a time in an unsupervised generative training setup.
Lee et al.\cite{lee2009convolutional} presented a hierarchical generative model, \textit{convolutional deep belief network}, to learn hierachical representation.
A couple of works\cite{erhan2009difficulty,erhan2010does,bengio2012deep} highlighted the advantage of unsupervised pre-training compared to the random initialization, connecting unsupervised pre-training to either a norm of regularization or better disentangling the sample variations.
However, xavier initialization\cite{glorot2010understanding} shorten the gap between the unsupervised pre-trained representations and random initialization.
Unsupervised deep representation learning is in general not comparable to supervised representation learning given large scale dataset is available.
\footnote{J: Citation needed.}
Supervised pre-training even in the presence of annotation errors is expected to outperform unsupervised pre-training because more information is provided.
\footnote{J: Evidence/Experiment needed!}
\textit{TODO Semi-supervised representation learning}

\paragraph{{Deep Learning with Noisy Labels}}

\textit{Robustness analysis}
Deep Learning is Robust to Massive Label Noise \cite{rolnick2017deep}

\textit{Entropy regularization}
Training deep neural networks on noisy labels with bootstrapping \cite{reed2014training}
Regularizing Neural Networks by Penalizing Confident Output Distributions \cite{pereyra2017regularizing}


\paragraph{Positive and Unlabeled Learning}
